# .github/workflows/scrape-on-demand.yml
name: Scrape Manga Chapter
on:
    repository_dispatch:
        types: [scrape-manga]

jobs:
    scrape:
        runs-on: ubuntu-latest
        timeout-minutes: 350
        steps:
            - uses: actions/checkout@v3

            - name: Set up Python
              uses: actions/setup-python@v4
              with:
                  python-version: "3.10"

            - name: Install dependencies
              run: |
                  pip install requests beautifulsoup4 cloudinary

            - name: Run scraper for specific manga
              env:
                  CLOUDINARY_CLOUD_NAME: ${{ secrets.CLOUDINARY_CLOUD_NAME }}
                  CLOUDINARY_API_KEY: ${{ secrets.CLOUDINARY_API_KEY }}
                  CLOUDINARY_API_SECRET: ${{ secrets.CLOUDINARY_API_SECRET }}
                  MANGA_SLUG: ${{ github.event.client_payload.manga_slug }}
                  MANGA_URL: ${{ github.event.client_payload.manga_url }}
              run: |
                  python scrape_new_chapters.py "$MANGA_SLUG" "$MANGA_URL"
